{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.nn.embedding_lookup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.placeholder(tf.int32, shape=[None])\n",
    "embedding = tf.Variable(np.identity(5, dtype=np.float32))\n",
    "input_embedding = tf.nn.embedding_lookup(embedding, input_ids)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(input_embedding, feed_dict={input_ids: [1, 2, 3, 0, 3, 2, 1, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.]],\n",
       "\n",
       "       [[ 0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tf.placeholder(tf.int32)\n",
    "input_embedding = tf.nn.embedding_lookup(embedding, input_ids)\n",
    "sess.run(input_embedding, feed_dict={input_ids:[[1, 2], [2, 1], [3, 3], [1, 1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.placeholder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `tf.nn.embedding_lookup` not found.\n"
     ]
    }
   ],
   "source": [
    "tf.nn.embedding_lookup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs & Sessions\n",
    "\n",
    "- TensorFlow uses a **dataflow graph** to represent your computation in terms of the dependencies between individual operations. \n",
    "- This leads to a low-level programming model in which you first define the dataflow graph, then create a TensorFlow **session** to run parts of the graph across a set of local and remote devices.\n",
    "- In a dataflow graph, the nodes represent units of computation, and the edges represent the data consumed or produced by a computation.\n",
    "- Dataflow advantages:\n",
    "  - Parallelism\n",
    "  - Distributed execution\n",
    "  - Compilation\n",
    "  - Portability\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.Graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A `Graph` contains a set of @{tf.Operation} objects, which represent units of computation; and\n",
    "@{tf.Tensor} objects, which represent the units of data that flow between operations.\n",
    "\n",
    "- A `Graph` instance supports an arbitrary number of \"collections\" that are identified by name. For convenience when building a large\n",
    "graph, collections can store groups of related objects: for\n",
    "example, the `tf.Variable` uses a collection (named\n",
    "@{tf.GraphKeys.GLOBAL_VARIABLES}) for\n",
    "all variables that are created during the construction of a graph. The caller\n",
    "may define additional collections by specifying a new name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tf.Graph contains two relevant kinds of information:\n",
    "- **Graph structure**. The nodes and edges of the graph, indicating how individual operations are composed together, but not prescribing how they should be used. The graph structure is like assembly code: inspecting it can convey some useful information, but it does not contain all of the useful context that source code conveys.\n",
    "- **Graph collections**. TensorFlow provides a general mechanism for storing collections of metadata in a tf.Graph. The tf.add_to_collection function enables you to associate a list of objects with a key (where tf.GraphKeys defines some of the standard keys), and tf.get_collection enables you to look up all objects associated with a key. Many parts of the TensorFlow library use this facility: for example, when you create a tf.Variable, it is added by default to collections representing \"global variables\" and \"trainable variables\". When you later come to create a tf.train.Saver or tf.train.Optimizer, the variables in these collections are used as the default arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TensorFlow provides a default graph that is an implicit argument to all API functions in the same context.\n",
    "- Calling tf.constant(42.0) creates a single tf.Operation that produces the value 42.0, adds it to the default graph, and returns a tf.Tensor that represents the value of the constant.\n",
    "- Calling tf.matmul(x, y) creates a single tf.Operation that multiplies the values of tf.Tensor objects x and y, adds it to the default graph, and returns a tf.Tensor that represents the result of the multiplication.\n",
    "- Executing v = tf.Variable(0) adds to the graph a tf.Operation that will store a writeable tensor value that persists between tf.Session.run calls. The tf.Variable object wraps this operation, and can be used like a tensor, which will read the current value of the stored value. The tf.Variable object also has methods such as assign and assign_add that create tf.Operation objects that, when executed, update the stored value. (See Variables for more information about variables.)\n",
    "- Calling tf.train.Optimizer.minimize will add operations and tensors to the default graph that calculate gradients, and return a tf.Operation that, when run, will apply those gradients to a set of variables.\n",
    "- Calling most functions in the TensorFlow API merely adds operations and tensors to the default graph, but does not perform the actual computation. nstead, you compose these functions until you have a tf.Tensor or tf.Operation that represents the overall computation--such as performing one step of gradient descent--and then pass that object to a tf.Session to perform the computation.\n",
    "- A tf.Graph object defines a namespace for the tf.Operation objects it contains. \n",
    "  - Each API function that creates a new tf.Operation or returns a new tf.Tensor accepts an optional name argument.\n",
    "  - tf.constant(42.0, name=\"answer\") creates a new tf.Operation named \"answer\" and returns a tf.Tensor named \"answer:0\". If the default graph already contained an operation named \"answer\", the TensorFlow would append \"_1\", \"_2\", and so on to the name, in order to make it unique.\n",
    "  - The tf.name_scope function makes it possible to add a name scope prefix to all operations created in a particular context. The current name scope prefix is a \"/\"-delimited list of the names of all active tf.name_scope context managers. If a name scope has already been used in the current context, TensorFlow appens \"_1\", \"_2\", and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'c:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_0 = tf.constant(0, name=\"c\")  # => operation named \"c\"\n",
    "c_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'c_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_1 = tf.constant(2, name=\"c\")\n",
    "c_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name scopes add a prefix to all operations created in the same context.\n",
    "with tf.name_scope(\"outer\"):\n",
    "    c_2 = tf.constant(2, name=\"c\")\n",
    "    # Name scopes nest like paths in a hierarchical file system.\n",
    "    with tf.name_scope(\"inner\"):\n",
    "        c_3 = tf.constant(3, name=\"c\")\n",
    "    # Exiting a name scope context will return to the previous prefix.\n",
    "    c_4 = tf.constant(4, name=\"c\")  # => operation named \"outer/c_1\"\n",
    "    # Already-used name scopes will be \"uniquified\".\n",
    "    with tf.name_scope(\"inner\"):\n",
    "        c_5 = tf.constant(5, name=\"c\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'outer/c:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'outer/inner/c:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'outer/c_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'outer/inner_1/c:0' shape=() dtype=int32>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_2, c_3, c_4, c_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that tf.Tensor objects are implicitly named after the `tf.Operation` that produces the tensor as output. \n",
    "A tensor name has the form `\"<OP_NAME>:<i>\"` where:\n",
    "\n",
    "- `\"<OP_NAME>\"` is the name of the operation that produces it.\n",
    "- `\"<i>\"` is an integer representing the index of that tensor among the operation's outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placing operations on different devices\n",
    "\n",
    "- A device specification has the following form:\n",
    "`/job:<JOB_NAME>/task:<TASK_INDEX>/device:<DEVICE_TYPE>:<DEVICE_INDEX>`\n",
    "\n",
    "> https://www.tensorflow.org/programmers_guide/graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are running in a single-machine configuration with a single GPU, you might use tf.device to pin some operations to the CPU and GPU:\n",
    "\n",
    "# Operations created outside either context will run on the \"best possible\"\n",
    "# device. For example, if you have a GPU and a CPU available, and the operation\n",
    "# has a GPU implementation, TensorFlow will choose the GPU.\n",
    "weights = tf.random_normal(...)\n",
    "\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "  # Operations created in this context will be pinned to the CPU.\n",
    "  img = tf.decode_jpeg(tf.read_file(\"img.jpg\"))\n",
    "\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "  # Operations created in this context will be pinned to the GPU.\n",
    "  result = tf.matmul(weights, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor-like objects\n",
    "For convenience, these functions will accept a tensor-like object in place of a tf.Tensor, and implicitly convert it to a `tf.Tensor` using the `tf.convert_to_tensor` method. Tensor-like objects include elements of the following types:\n",
    "- tf.Tensor\n",
    "- tf.Variable\n",
    "- numpy.ndarray\n",
    "- list (and lists of tensor-like objects)\n",
    "- Scalar Python types: bool, float, int, str\n",
    "\n",
    "> **By default, TensorFlow will create a new tf.Tensor each time you use the same tensor-like object**. If the tensor-like object is large (e.g. a numpy.ndarray containing a set of training examples) and you use it multiple times, you may run out of memory. To avoid this, manually call tf.convert_to_tensor on the tensor-like object once and use the returned tf.Tensor instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'add_3:0' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'add_4:0' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'add_5:0' shape=(2, 2) dtype=float32>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def my_func(arg):\n",
    "  arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "  return tf.matmul(arg, arg) + arg\n",
    "\n",
    "# The following calls are equivalent.\n",
    "value_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))\n",
    "value_2 = my_func([[1.0, 2.0], [3.0, 4.0]])\n",
    "value_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))\n",
    "\n",
    "value_1, value_2, value_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.Session \n",
    "- TensorFlow uses the tf.Session class to represent a connection between the client program---typically a Python program\n",
    "- A tf.Session object provides access to devices in the local machine, and remote devices using the distributed TensorFlow runtime. It also **caches** information about your tf.Graph so that you can efficiently run the same computation multiple times.\n",
    "- Since a tf.Session owns physical resources (such as GPUs and network connections), it is typically used as a context manager (in a with block) that automatically closes the session when you exit the block. It is also possible to create a session without using a with block, but you should explicitly call tf.Session.close when you are finished with it to free the resources.\n",
    "-  Higher-level APIs such as `tf.train.MonitoredTrainingSession` or `tf.estimator.Estimator` will create and manage a tf.Session for you. \n",
    "- By default, a new tf.Session will be bound to---and only able to run operations in---the current default graph.\n",
    "- [tf.ConfigProto](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/core/protobuf/config.proto)\n",
    "- The `tf.Session.run` method is the main mechanism for running a tf.Operation or evaluating a tf.Tensor. You can pass one or more tf.Operation or tf.Tensor objects to tf.Session.run, and TensorFlow will execute the operations that are needed to compute the result.\n",
    "- `tf.Session.run` requires you to specify a list of fetches, which determine the return values, and may be a tf.Operation, a tf.Tensor, or a tensor-like type such as tf.Variable. These fetches determine what subgraph of the overall tf.Graph must be executed to produce the result.\n",
    "- tf.Session.run also optionally takes a dictionary of feeds, which is a mapping from tf.Tensor objects (typically tf.placeholder tensors) to values (typically Python scalars, lists, or NumPy arrays) that will be substituted for those tensors in the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.client.session.Session object at 0x7f8139d868d0>\n"
     ]
    }
   ],
   "source": [
    "# Create a default in-process session.\n",
    "with tf.Session() as sess:\n",
    "    print(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a remote session.\n",
    "with tf.Session(\"grpc://example.org:2222\"):\n",
    "    # ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00366294 0.99633706]\n",
      " [0.4479277  0.5520723 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[37.0, -23.0], [1.0, 4.0]])\n",
    "w = tf.Variable(tf.random_uniform([2, 2]))\n",
    "y = tf.matmul(x, w)\n",
    "output = tf.nn.softmax(y)\n",
    "init_op = w.initializer\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Run the initializer on `w`.\n",
    "  sess.run(init_op)\n",
    "\n",
    "  # Evaluate `output`. `sess.run(output)` will return a NumPy array containing\n",
    "  # the result of the computation.\n",
    "  print(sess.run(output))\n",
    "\n",
    "  # Evaluate `y` and `output`. Note that `y` will only be computed once, and its\n",
    "  # result used both to return `y_val` and as an input to the `tf.nn.softmax()`\n",
    "  # op. Both `y_val` and `output_val` will be NumPy arrays.\n",
    "  y_val, output_val = sess.run([y, output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 4. 9.]\n",
      "[ 0.  0. 25.]\n",
      "<class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>\n",
      "<class 'ValueError'>\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Define a placeholder that expects a vector of three floating-point values,\n",
    "# and a computation that depends on it.\n",
    "x = tf.placeholder(tf.float32, shape=[3])\n",
    "y = tf.square(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Feeding a value changes the result that is returned when you evaluate `y`.\n",
    "    print(sess.run(y, {x: [1.0, 2.0, 3.0]}))  # => \"[1.0, 4.0, 9.0]\"\n",
    "    print(sess.run(y, {x: [0.0, 0.0, 5.0]}))  # => \"[0.0, 0.0, 25.0]\"\n",
    "\n",
    "  # Raises `tf.errors.InvalidArgumentError`, because you must feed a value for\n",
    "  # a `tf.placeholder()` when evaluating a tensor that depends on it.\n",
    "    try:\n",
    "        sess.run(y)\n",
    "    except Exception as e:\n",
    "        print(type(e))\n",
    "\n",
    "  # Raises `ValueError`, because the shape of `37.0` does not match the shape\n",
    "  # of placeholder `x`.\n",
    "    try: \n",
    "        sess.run(y, {x: 37.0})\n",
    "    except ValueError as e:\n",
    "        print(type(e))\n",
    "    print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[node {\n",
      "  name: \"MatMul_10/a\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\000\\024B\\000\\000\\270\\301\\000\\000\\200?\\000\\000\\200@\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_4/shape\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\002\\000\\000\\000\\002\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_4/RandomUniform\"\n",
      "  op: \"RandomUniform\"\n",
      "  input: \"random_uniform_4/shape\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"seed\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"seed2\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_4/sub\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        tensor_content: \"\\000\\000\\200?\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_4/mul\"\n",
      "  op: \"Mul\"\n",
      "  input: \"random_uniform_4/RandomUniform\"\n",
      "  input: \"random_uniform_4/sub\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_4/min\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_4\"\n",
      "  op: \"Add\"\n",
      "  input: \"random_uniform_4/mul\"\n",
      "  input: \"random_uniform_4/min\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"MatMul_10\"\n",
      "  op: \"MatMul\"\n",
      "  input: \"MatMul_10/a\"\n",
      "  input: \"random_uniform_4\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_a\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_b\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"_retval_MatMul_10_0_0\"\n",
      "  op: \"_Retval\"\n",
      "  input: \"MatMul_10\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"index\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "library {\n",
      "}\n",
      "versions {\n",
      "  producer: 24\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "y = tf.matmul([[37.0, -23.0], [1.0, 4.0]], tf.random_uniform([2, 2]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Define options for the `sess.run()` call.\n",
    "  options = tf.RunOptions()\n",
    "  options.output_partition_graphs = True\n",
    "  options.trace_level = tf.RunOptions.FULL_TRACE\n",
    "\n",
    "  # Define a container for the returned metadata.\n",
    "  metadata = tf.RunMetadata()\n",
    "\n",
    "  sess.run(y, options=options, run_metadata=metadata)\n",
    "\n",
    "  # Print the subgraphs that executed on each device.\n",
    "  pprint.pprint(metadata.partition_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_stats {\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  node_stats {\n",
      "    node_name: \"_SOURCE\"\n",
      "    all_start_micros: 1516257747486266\n",
      "    op_start_rel_micros: 2\n",
      "    op_end_rel_micros: 2\n",
      "    all_end_rel_micros: 6\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    timeline_label: \"_SOURCE = NoOp()\"\n",
      "    scheduled_micros: 1516257747486227\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"MatMul_10/a\"\n",
      "    all_start_micros: 1516257747486277\n",
      "    all_end_rel_micros: 4\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 82306880\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"MatMul_10/a = Const()\"\n",
      "    scheduled_micros: 1516257747486272\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_4/shape\"\n",
      "    all_start_micros: 1516257747486282\n",
      "    all_end_rel_micros: 1\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_INT32\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 8\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 64093632\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_4/shape = Const()\"\n",
      "    scheduled_micros: 1516257747486281\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_4/sub\"\n",
      "    all_start_micros: 1516257747486288\n",
      "    all_end_rel_micros: 1\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 4\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 85679808\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_4/sub = Const()\"\n",
      "    scheduled_micros: 1516257747486283\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_4/min\"\n",
      "    all_start_micros: 1516257747486290\n",
      "    all_end_rel_micros: 1\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 4\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 82147968\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_4/min = Const()\"\n",
      "    scheduled_micros: 1516257747486289\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_4/RandomUniform\"\n",
      "    all_start_micros: 1516257747486293\n",
      "    op_start_rel_micros: 2\n",
      "    op_end_rel_micros: 9\n",
      "    all_end_rel_micros: 13\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "      total_bytes: 16\n",
      "      peak_bytes: 16\n",
      "      live_bytes: 16\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          has_single_reference: true\n",
      "          ptr: 140192295947264\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_4/RandomUniform = RandomUniform(random_uniform_4/shape)\"\n",
      "    scheduled_micros: 1516257747486284\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_4/mul\"\n",
      "    all_start_micros: 1516257747486309\n",
      "    op_end_rel_micros: 4\n",
      "    all_end_rel_micros: 5\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          ptr: 140192295947264\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_4/mul = Mul(random_uniform_4/RandomUniform, random_uniform_4/sub)\"\n",
      "    scheduled_micros: 1516257747486306\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_4\"\n",
      "    all_start_micros: 1516257747486316\n",
      "    op_end_rel_micros: 1\n",
      "    all_end_rel_micros: 2\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          ptr: 140192295947264\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_4 = Add(random_uniform_4/mul, random_uniform_4/min)\"\n",
      "    scheduled_micros: 1516257747486314\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"MatMul_10\"\n",
      "    all_start_micros: 1516257747486319\n",
      "    op_end_rel_micros: 5\n",
      "    all_end_rel_micros: 7\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "      total_bytes: 16\n",
      "      peak_bytes: 16\n",
      "      live_bytes: 16\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          has_single_reference: true\n",
      "          ptr: 140192295951392\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"MatMul_10 = MatMul(MatMul_10/a, random_uniform_4)\"\n",
      "    scheduled_micros: 1516257747486318\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"_retval_MatMul_10_0_0\"\n",
      "    all_start_micros: 1516257747486333\n",
      "    op_end_rel_micros: 1\n",
      "    all_end_rel_micros: 2\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    timeline_label: \"_retval_MatMul_10_0_0 = _Retval(MatMul_10)\"\n",
      "    scheduled_micros: 1516257747486326\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  # Print the timings of each operation that executed.\n",
    "  pprint.pprint(metadata.step_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.RunOptions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
